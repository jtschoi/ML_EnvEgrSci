{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c75e6c3-e0b1-4de2-bc8f-faeddccb37e5",
   "metadata": {},
   "source": [
    "## A. Importing necessary files and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c52c4c1-268a-4939-9ebf-df7d2dd5aa7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6f6e80-931e-4cdb-8422-6c5714f384a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 11:41:27.492953: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-03 11:41:27.534224: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "CWD = Path(os.getcwd())\n",
    "PYFILES_PATH = CWD.parent / \"PyFiles\"\n",
    "sys.path.append(str(PYFILES_PATH))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# these are in the PYFILES_PATH\n",
    "from utils import *\n",
    "import settings as bc\n",
    "import my_neural_networks as my_nn\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb53a239-ffe2-49ce-a5a2-625db77b5576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.dpi\"] = 400\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b071d391-cf6d-4b73-910c-53c66899412c",
   "metadata": {},
   "source": [
    "## B. Data preprocessing\n",
    "\n",
    "### 1. Importing the datasets into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5dece0-b46e-4e95-8957-95ddcf7e0169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add9f3c4b72a4a80bf87a9331e220b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6af2b551ac44d4e93f0f9c7384641c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a344d75103e435f9f87ae26f4632a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1950671108da48f582acf2e0c12239e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `prepare_predictor` and `prepare_predictand` are all in\n",
    "# the file `utils.py`.\n",
    "train_scenarios = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\", \"hist-aer\", \"hist-GHG\"]\n",
    "test_scenario = \"ssp245\"\n",
    "\n",
    "X_train_xr, X_length = prepare_predictor(train_scenarios, bc.TRAIN_PATH)\n",
    "y_train_xr, y_length = prepare_predictand(train_scenarios, bc.TRAIN_PATH)\n",
    "\n",
    "X_test_xr, _ = prepare_predictor(test_scenario, bc.TEST_PATH)\n",
    "y_test_xr, _ = prepare_predictand(test_scenario, bc.TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa952f-ed6e-470b-b45e-1d5b6c0f9fe9",
   "metadata": {},
   "source": [
    "### 2. Select relevant variables\n",
    "\n",
    "We select the predictors as CO2 and CH4, and the predictand as `tas`. Notice that the `y` variable data (`tas`) are formatted differently from the vanilla NN example, as they are now **2D** maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893db484-9670-4751-8633-4c5ea56ffa30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(\n",
    "    data={x: X_train_xr[x] for x in [\"CO2\", \"CH4\"]},\n",
    "    index=X_train_xr[\"CO2\"].coords[\"time\"].values,\n",
    ")\n",
    "X_test_df = pd.DataFrame(\n",
    "    data={x: X_test_xr[x] for x in [\"CO2\", \"CH4\"]},\n",
    "    index=X_test_xr[\"CO2\"].coords[\"time\"].values,\n",
    ")\n",
    "\n",
    "# no \"flattening\"! Keeping the 2D structure for CNN implementation\n",
    "y_train = y_train_xr[\"tas\"].data\n",
    "y_test = y_test_xr[\"tas\"].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de36f913-245f-49a7-bbde-1248cbdcacac",
   "metadata": {},
   "source": [
    "### 3. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "750452ac-681e-4b4b-81c8-cb71e0a3e929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimesions for test data (predictor) are: (86, 2)\n",
      "The dimesions for training data (predictor) are: (753, 2)\n",
      "The dimesions for test data (predictand) are: (86, 96, 144)\n",
      "The dimesions for training data (predictand) are: (753, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "normalization = [X_train_df.mean(), X_train_df.std()]\n",
    "X_train_df = (X_train_df - normalization[0]) / normalization[1]\n",
    "X_test_df = (X_test_df - normalization[0]) / normalization[1]\n",
    "\n",
    "X_train, X_test = X_train_df.to_numpy(), X_test_df.to_numpy()\n",
    "\n",
    "for i in [\"predictor\", \"predictand\"]:\n",
    "    for j in [\"test\", \"training\"]:\n",
    "        info = X_train\n",
    "        if (j == \"test\") and (i == \"predictor\"):\n",
    "            info = X_test\n",
    "        elif (j == \"test\") and (i == \"predictand\"):\n",
    "            info = y_test\n",
    "        elif (j == \"training\") and (i == \"predictand\"):\n",
    "            info = y_train\n",
    "\n",
    "        dimensions = \", \".join([str(x) for x in info.shape])\n",
    "        print(f\"The dimesions for {j} data ({i}) are: ({dimensions})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46bd994-4b3f-4f7c-bc98-7b05e781569a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61352807-29b3-4465-b589-90b2419bc25a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(info.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
